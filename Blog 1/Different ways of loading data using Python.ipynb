{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this article we will be working with **different ways of reading a dataset using python**. The motivation behind writing this blog is when I searched about the same and got very limited sites who are actually shifting their focus from **CSV format** to any other available method, though there is no doubt about the fact that **pd.read_csv()** is one of the best way of reading dataset using python (**pandas-** particularly) but while working in real-time project we should know different methods of **loading, accessing the dataset**  as no-one knows what turns out to be handy at what time.\n",
    "\n",
    "So, let's first see on what kind of methods we are gonna be working then straightaway implement it using **Python.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data in Python using 5 different methods\n",
    "\n",
    "1. **Manually loading a file:** This is the first and the most **picular** and **less recommended** way to load our dataset as it requires lot of code part to even read one tuple from the DataFrame. This way comes into picture when dataset **doesn't have any particular pattern to identify** neither it have a **specific pattern.** \n",
    "\n",
    "\n",
    "2. Using **np.loadtxt:** One of the **numpy methods** for loading different type of data though it is only supported when we have a data in a certain format i.e. **pattern recognizable** unlike the manual way of reading the dataset.\n",
    "\n",
    "\n",
    "3. Using **np.genfromtxt:** This is another numpy way to read the data but this time it is much better than the **np.loadtxt()** method as it recognize the presence of **column header** by its own which the previous one is not capable to follow on. Along with that it can also detect the **right data type** of each column.\n",
    "\n",
    "\n",
    "4. Using **pd.read_csv:** Here is the most recommended and widely used method for **reading, writing and manipulating** the dataset where it only deals with **CSV formatted** data but the support of various parameters makes it absolutely **gold mine for data analyst** to work with different sort of data (they should have specific format).\n",
    "\n",
    "\n",
    "5. Using **pickle:** Last but not the least we will also use **pickle** to read in the dataset which is present in the **binary format**. So far we chose pickle to **only save the model** but the capabilities of this module is much more than that which we will explore in the coming article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required python libraries\n",
    "\n",
    "The first thing for using the python supported libraries we first need to import them to establish the environment and configuration. Here are the following modules that we will import.\n",
    "\n",
    "* **Numpy:** Numpy is mainly used to perform mathematical calculations though here we will use it to access the methods for our needs, they are: **np.loadtxt()** and **np.genfromtxt()**.\n",
    "\n",
    "* **Pandas:** For **converting** the unsorted data into the **correctly formatted dataset** on top of that we can lately manipulate and draw some insights as well. \n",
    "\n",
    "* **Pickle:** For using pickle module we also need to import the same independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "file_dir = \"load_dataset_blog.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have imported the modules that we might need along with that stored the path of the dataset in a variable for so that we don't have to write it again and again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually reading the dataset\n",
    "\n",
    "Here comes the first method where we will use the **open** and **readLines** method by looping through each line. For that reason only it is the least recommended and exceptionally used method as it is not flexible and fessible enough to make our task easier instead a bit hectic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    float64\n",
      "B    float64\n",
      "C    float64\n",
      "D    float64\n",
      "E    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.276</td>\n",
       "      <td>21.400</td>\n",
       "      <td>63.957</td>\n",
       "      <td>216.204</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002</td>\n",
       "      <td>21.950</td>\n",
       "      <td>61.697</td>\n",
       "      <td>204.484</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114</td>\n",
       "      <td>22.454</td>\n",
       "      <td>63.522</td>\n",
       "      <td>205.608</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.133</td>\n",
       "      <td>22.494</td>\n",
       "      <td>61.590</td>\n",
       "      <td>206.565</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845</td>\n",
       "      <td>21.654</td>\n",
       "      <td>63.729</td>\n",
       "      <td>201.289</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A       B       C        D      E\n",
       "0  1.276  21.400  63.957  216.204  528.0\n",
       "1  1.002  21.950  61.697  204.484  514.0\n",
       "2  1.114  22.454  63.522  205.608  514.0\n",
       "3  1.133  22.494  61.590  206.565  501.0\n",
       "4  0.845  21.654  63.729  201.289  532.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_head = None\n",
    "data_rows = []\n",
    "with open(file_dir) as f:\n",
    "    for lines in f.readlines():\n",
    "        values = lines.replace(\"\\n\", \"\").split(\",\")\n",
    "        if cols_head is None:\n",
    "            cols_head = values\n",
    "        else:\n",
    "            data_rows.append([float(x) for x in values])\n",
    "manual = pd.DataFrame(data_rows, columns=cols_head)\n",
    "print(manual.dtypes)\n",
    "manual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code breakdown:**\n",
    "\n",
    "1. Firstly, we are using instance of **with** and **open** function to read the dataset. Then for accessing each tuple we have to loop through the complete dataset till the end of the file (**readLines()**).\n",
    "\n",
    "2. Then, if one will notice that we have also used the **replace** function as after every line there is the line break which is not needed while building up the DataFrame.\n",
    "\n",
    "3. Then at the last seperating the **column names** and **data (tuples)**. Note that for storing data values we are using the **list comprehension** method. At the last using pandas's **DataFrame** function the unstructured data is converted into pandas dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.loadtxt\n",
    "\n",
    "This method is widely used for the **simple data arrays** that require very **minimal formatting** i.e. for simple values where much changes are not needed. Here we use some mandatory parameters as well that will be discussed in no time. We can also use the **np.savetxt** function to save the data read/loaded by **np.loadtxt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[[  1.276  21.4    63.957 216.204 528.   ]\n",
      " [  1.002  21.95   61.697 204.484 514.   ]\n",
      " [  1.114  22.454  63.522 205.608 514.   ]\n",
      " [  1.133  22.494  61.59  206.565 501.   ]\n",
      " [  0.845  21.654  63.729 201.289 532.   ]]\n"
     ]
    }
   ],
   "source": [
    "d1 = np.loadtxt(filename, skiprows=1, delimiter=\",\")\n",
    "print(d1.dtype)\n",
    "print(d1[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** np.loadtxt() method is used with relevant parameters like, **filename** to get the path of the dataset, **skiprows**, which is responsible to decide that the first row (column headers) should be skipped or not and the **delimeter** to specify how the values are seperated as in our case its comma (\",\").\n",
    "\n",
    "For printing each row (5 here) we are using the **slicing** concept of python list data type. Note that in output we are not able to see the **column header** because **skiprows is set to 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.genfromtxt\n",
    "\n",
    "This is another function supported by numpy that is more flexible than the **np.loadtxt** function as **np.genfromtxt** have the better parsing functionality along with that it supports different **types of data**, **named column** and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', '<f8'), ('B', '<f8'), ('C', '<f8'), ('D', '<f8'), ('E', '<i8')]\n",
      "[(1.276, 21.4  , 63.957, 216.204, 528)\n",
      " (1.002, 21.95 , 61.697, 204.484, 514)\n",
      " (1.114, 22.454, 63.522, 205.608, 514)\n",
      " (1.133, 22.494, 61.59 , 206.565, 501)\n",
      " (0.845, 21.654, 63.729, 201.289, 532)]\n"
     ]
    }
   ],
   "source": [
    "d2 = np.genfromtxt(filename, delimiter=\",\", names=True, dtype=None)\n",
    "print(d2.dtype)\n",
    "print(d2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** Starting with focussing on the parameter where filename is used to access the path of the dataset, then delimiter is tagged as comma as we are working with CSV file, names are set to be True so that columns are visible, lastly, dtype is set to None so that numpy will autodetect the column type (('E', **'<i8'**) - integer detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.read_csv\n",
    "\n",
    "By far the best and most flexible CSV/txt file reader. Highly, highly recommended. If you don't believe me, just look at the [obscene number of arguments you can parse to read_csv in the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    float64\n",
      "B    float64\n",
      "C    float64\n",
      "D    float64\n",
      "E      int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.276</td>\n",
       "      <td>21.400</td>\n",
       "      <td>63.957</td>\n",
       "      <td>216.204</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002</td>\n",
       "      <td>21.950</td>\n",
       "      <td>61.697</td>\n",
       "      <td>204.484</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114</td>\n",
       "      <td>22.454</td>\n",
       "      <td>63.522</td>\n",
       "      <td>205.608</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.133</td>\n",
       "      <td>22.494</td>\n",
       "      <td>61.590</td>\n",
       "      <td>206.565</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.845</td>\n",
       "      <td>21.654</td>\n",
       "      <td>63.729</td>\n",
       "      <td>201.289</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A       B       C        D    E\n",
       "0  1.276  21.400  63.957  216.204  528\n",
       "1  1.002  21.950  61.697  204.484  514\n",
       "2  1.114  22.454  63.522  205.608  514\n",
       "3  1.133  22.494  61.590  206.565  501\n",
       "4  0.845  21.654  63.729  201.289  532"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = pd.read_csv(filename)\n",
    "print(d3.dtypes)\n",
    "d3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** There is not much to discuss here as reading the CSV file from pandas is something from where we started our data science journey. Note that just like previous function it can also detect the real data type of each column (**E - int64**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle\n",
    "\n",
    "For when your data or object is not a nice 2D array and harder to save as something human readable. Note that if you just have a 3D, 4D... ND array of all the same type, you can also use **np.save** which will save an arbitrary numpy array in binary format. Super quick to save, super quick to load in, and small file size.\n",
    "\n",
    "Pickle is for everything that is more complicated. You can save dictionaries, arrays, even objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    float64\n",
      "B    float64\n",
      "C    float64\n",
      "D    float64\n",
      "E      int32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.276405</td>\n",
       "      <td>21.400157</td>\n",
       "      <td>63.957476</td>\n",
       "      <td>216.204466</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002272</td>\n",
       "      <td>21.950088</td>\n",
       "      <td>61.697286</td>\n",
       "      <td>204.483906</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114404</td>\n",
       "      <td>22.454274</td>\n",
       "      <td>63.522075</td>\n",
       "      <td>205.608375</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.133367</td>\n",
       "      <td>22.494079</td>\n",
       "      <td>61.589683</td>\n",
       "      <td>206.565339</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.844701</td>\n",
       "      <td>21.653619</td>\n",
       "      <td>63.728872</td>\n",
       "      <td>201.289175</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A          B          C           D    E\n",
       "0  1.276405  21.400157  63.957476  216.204466  528\n",
       "1  1.002272  21.950088  61.697286  204.483906  514\n",
       "2  1.114404  22.454274  63.522075  205.608375  514\n",
       "3  1.133367  22.494079  61.589683  206.565339  501\n",
       "4  0.844701  21.653619  63.728872  201.289175  532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"load_pickle.pickle\", \"rb\") as f:\n",
    "    d4 = pickle.load(f)\n",
    "print(d4.dtypes)\n",
    "d4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** The last method for loading/reading the data is Pickle, we have often used this for only saving the model but here we can see that it can also read the same in the **read mode** (note that it is serialized in the binary format). For loading the pickle file we use the **load** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Here we are in the last part of the article, In this article we went through learning the different ways of how the data can be read using **numerous function available with Python**. While practically looking at the differences we also learned the limitations of each way and **when to use what**.\n",
    "\n",
    "1. First we started off with manually reading the file and came to the conclusion that it is highly not recommended to use this method as it is **time consuming**.\n",
    "\n",
    "2. Then we discussed two methods that are supported by numpy (**np.loadtxt** and **np.genfromtxt**) where the second one seems **more optimal** as it was even able to detect the right data type for each column.\n",
    "\n",
    "3. At the last we parsed through last two ways (**read_csv** and **pickle**) where we got an interesting insight- **pickle is just not for saving models**, but also training/testing dataset, dictionaries, objects and what not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
